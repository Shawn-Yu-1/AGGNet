{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:00<00:00, 1224.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3031959533691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from data.util.mask import bbox2mask, brush_stroke_mask, random_bbox, get_irregular_mask\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "path = \"./mask/irregular/0.4-0.6/\"\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "rate = 0\n",
    "for i in tqdm(range(400)):\n",
    "    # regular_mask = bbox2mask((256, 256), random_bbox())\n",
    "    # irregular_mask = brush_stroke_mask((256,256), )\n",
    "    # mask = regular_mask | irregular_mask\n",
    "    mask = get_irregular_mask((256, 256), (0.2, 0.4))\n",
    "    rate += np.sum(mask) / (256*256)\n",
    "    mask = mask.transpose(2,0,1)\n",
    "    mask = mask.squeeze()\n",
    "    # img = Image.fromarray(mask).convert(\"L\")\n",
    "    # img.save(f\"{path}{i}.png\")\n",
    "print(rate / 400)\n",
    "    # mask = np.asarray(Image.open(\"./mask/0.png\"))\n",
    "    # print(mask)\n",
    "    # img = np.asarray(Image.open(\"./mask/irregular/100.png\"))\n",
    "    # plt.imshow(mask)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [02:25<00:00, 34.40it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"/data/dataset/places365/val/\"\n",
    "mask_dir = \"./mask/irregular/0.2-0.4/\"\n",
    "output = \"./test_image/places2/0.2-0.4/\"\n",
    "if not os.path.exists(output):\n",
    "    os.makedirs(output, exist_ok=True)\n",
    "\n",
    "os.makedirs(output+\"images\", exist_ok=True)\n",
    "os.makedirs(output+\"masks\", exist_ok=True)\n",
    "imgs = []\n",
    "\n",
    "for root, _, files in os.walk(data_path):\n",
    "    for file in files:\n",
    "        imgs.append(os.path.join(root, file))\n",
    "\n",
    "imgs = sorted(imgs)\n",
    "count = 0\n",
    "for img_path in tqdm(imgs[:5000]):\n",
    "    name = img_path.split(\"/\")[-1].replace(\"jpg\", \"png\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img = np.array(img).transpose(2,0,1)\n",
    "    mask = Image.open(mask_dir+f\"{count % 400}.png\")\n",
    "    mask = np.array(mask)\n",
    "    img = img*(1-mask) + mask * 255\n",
    "    mask = mask * 255\n",
    "    img = Image.fromarray(img.transpose(1,2,0))\n",
    "    mask = Image.fromarray(mask)\n",
    "    img.save(output+\"images/\"+name)\n",
    "    mask.save(output+\"masks/\"+name)\n",
    "    count += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04409027099609375\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# print(np.random.normal(0, 1, (10, 10)))\n",
    "# print(torch.rand((10,10)))\n",
    "# print(torch.randn((10, 10)))\n",
    "img = Image.open(\"./mask/irregular/0.1-0.2/0.png\")\n",
    "img = np.array(img)\n",
    "rate = np.sum(img) / (512*512)\n",
    "print(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5918/17943 [01:52<03:44, 53.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "066590.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 13184/17943 [04:09<01:30, 52.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/yuxk/mycode/AGGNets/get_mask.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmyserver/home/yuxk/mycode/AGGNets/get_mask.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m targets \u001b[39m=\u001b[39m tf(target)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmyserver/home/yuxk/mycode/AGGNets/get_mask.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m img_path \u001b[39min\u001b[39;00m tqdm(imgs):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmyserver/home/yuxk/mycode/AGGNets/get_mask.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mopen(img_path)\u001b[39m.\u001b[39;49mresize((\u001b[39m256\u001b[39;49m,\u001b[39m256\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmyserver/home/yuxk/mycode/AGGNets/get_mask.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m tf(img)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmyserver/home/yuxk/mycode/AGGNets/get_mask.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     score \u001b[39m=\u001b[39m ssim(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mcuda(), targets\u001b[39m.\u001b[39mcuda())\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/PIL/Image.py:2046\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2042\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreducing_gap must be 1.0 or greater\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2044\u001b[0m size \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(size)\n\u001b[0;32m-> 2046\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   2047\u001b[0m \u001b[39mif\u001b[39;00m box \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2048\u001b[0m     box \u001b[39m=\u001b[39m (\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize\n",
      "File \u001b[0;32m~/.conda/envs/pytorch/lib/python3.8/site-packages/PIL/ImageFile.py:257\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[1;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mimage file is truncated \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(b)\u001b[39m}\u001b[39;00m\u001b[39m bytes not processed)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    256\u001b[0m b \u001b[39m=\u001b[39m b \u001b[39m+\u001b[39m s\n\u001b[0;32m--> 257\u001b[0m n, err_code \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(b)\n\u001b[1;32m    258\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    259\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "from metrics.ssim import ssim\n",
    "import torch\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "path = \"/data/dataset/CelebA-HQ/train/female/\"\n",
    "imgs = []\n",
    "for root, _ ,files in os.walk(path):\n",
    "    for file in files:\n",
    "        imgs.append(os.path.join(root, file))\n",
    "\n",
    "target = Image.open(\"./1234321.jpg\").resize((256,256))\n",
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    "                         transforms.ConvertImageDtype(torch.float),\n",
    "                         transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5,0.5])])\n",
    "targets = tf(target)\n",
    "\n",
    "for img_path in tqdm(imgs):\n",
    "    img = Image.open(img_path).resize((256,256))\n",
    "    input = tf(img)\n",
    "    score = ssim(input.cuda(), targets.cuda())\n",
    "    if score > 0.70:\n",
    "        print(img_path.split(\"/\")[-1])\n",
    "        # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8323fe3177b887d173177365811fd4c4c7911cfb2ec97261f780e85626804da1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
